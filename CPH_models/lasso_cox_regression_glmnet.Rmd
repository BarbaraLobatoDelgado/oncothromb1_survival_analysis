---
title: "Lasso Cox Regression"
author: "Bárbara Lobato Delgado"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Settings and load libraries

```{r}
# Deactivate scientific notation
options(scipen = 999, max.print = 10000)

# Seed
seed = 2828
set.seed(seed)
```


```{r}
find_column_mismatch <- function(df1, df2) {
  # Find column mismatch
  missing_in_valid <- setdiff(colnames(df1), colnames(df2))
  extra_in_valid <- setdiff(colnames(df2), colnames(df1))
  
  if (length(missing_in_valid) > 0 || length(extra_in_valid) > 0) {
    msg <- c()
    if (length(missing_in_valid) > 0) {
      msg <- c(msg, sprintf("Columns missing in validation: %s", 
                            paste(missing_in_valid, collapse = ", ")))
    }
    if (length(extra_in_valid) > 0) {
      msg <- c(msg, sprintf("Extra columns in validation: %s",
                          paste(extra_in_valid, collapse = ", ")))
    }
    stop(paste(msg, collapse = "; "), call. = FALSE)
  }
}
```


```{r}
# Load libraries
pacman::p_load(
  an9elproject, 
  tidyverse,
  lubridate, 
  magrittr,
  fastDummies,
  glmnet,
  survival,
  survminer, 
  penalized,
  powerSurvEpi,
  car,
  StepReg,
  plotly,
  install = FALSE, update = FALSE
  )
```

## Load data

```{r cars}
# # Load time-dependent dataset
# oncoth1_td_dataset = read.csv(file = "/mnt/ir-bioinf02/home/blobato/oncothromb01/data/processed/oncoth1_td_dataset.csv")
```


```{r}
# Load an9elproject DB
oncoth1 <- get_project("oncothr1", version = "0.0.8005") 
```


```{r}
# Get data slot
oncoth1_data <- oncoth1$data
```


```{r}
# Get meaningful variables
oncoth1_survival_df <- oncoth1_data %>%
  filter(patient_inc_exc == "Included") %>%
  select(id, 
         patient_group,
         # Follow-up data
         censored_patient, # zero for censored patients (alive at the time point), one for dead
         follow_up_length_from_cancer_diagnosis_days, 
         # Covariates
         age_when_cancer_dx, 
         gender, 
         bmi_value, 
         performance_status_category_corrected_imp, 
         diabetes_mellitus,
         dyslipidemia, 
         arterial_hypertension, 
         tobacco_use_imp, 
         copd_imp, 
         venous_insufficiency_imp, 
         khorana_risk_score_imp, 
         two_groups_krs,
         previous_onco_surgery,
         tumor_surgically_removed, 
         primary_tumor_simplified, 
         tnm_stage,
         tnm_stage_grouped, 
         tnm_stage_two_groups, 
         histology_type_imp,
         mucinous_histology_imp,
         grade_histological_differentiation_imp,
         catheter_device_imp, 
         family_background_vte, 
         previous_vte,  
         previous_ate, 
         anticoag_tx_currently, 
         antiaggreg_tx_currently
         ) %>%
  # Create VTE variable
  mutate(VTE = ifelse(patient_group == "Case", 1, 0)) %>%
  select(-patient_group) %>%
  # Create dataset for survival analysis
  rename(death = censored_patient, 
         time = follow_up_length_from_cancer_diagnosis_days)
  
  
```


```{r}

  
```


```{r}
# Stop if there are missing values in dataset
stopifnot(!anyNA(oncoth1_survival_df))
```



```{r}
cols2select <- c(
 "VTE",
 "age_when_cancer_dx", 
 "gender", 
 "bmi_value", 
 "performance_status_category_corrected_imp", 
 "diabetes_mellitus",
 "dyslipidemia", 
 "arterial_hypertension", 
 "tobacco_use_imp", 
 # "copd_imp", 
 "venous_insufficiency_imp", 
 # "khorana_risk_score_imp",# correlated to a lot of features
 # "two_groups_krs", # correlated to a lot of features
 "previous_onco_surgery",
 "tumor_surgically_removed", 
 "primary_tumor_simplified", 
 # "tnm_stage",
 # "tnm_stage_grouped",
 "tnm_stage_two_groups",
 # "histology_type_imp", # unequal categories between train and validation set
 "mucinous_histology_imp",
 "grade_histological_differentiation_imp",
 # "catheter_device_imp", 
 "family_background_vte",
 "previous_vte",
 "previous_ate", 
 "anticoag_tx_currently", # unequal categories between train and validation set
 "antiaggreg_tx_currently"
 )
```


```{r}
process_data <- function(data, cols2select, apply_scaling = FALSE) {
  
  missing_cols <- setdiff(cols2select, colnames(data))
  if (length(missing_cols) > 0) {
    stop(paste("The following columns are missing from the data:", 
               paste(missing_cols, collapse = ", ")))
  }
  
  # Select columns as dependent variables
  data_selection <- data[, cols2select]
  
  # Convert yes/no columns into 1/0
  data_selection <- data_selection %>%
    mutate(
      across(
        .cols = where(~ (is.character(.) || is.factor(.)) && 
                        all(as.character(.) %in% c("Yes", "No"))), 
        .fns = ~ as.integer(as.character(.) == "Yes")
      )
    )
  
  # Transform other columns to numerical
  data_transf <- data_selection %>%
    mutate(grade_histological_differentiation_imp = as.numeric(case_when(
      str_starts(grade_histological_differentiation_imp, "Well") ~ 1,
      str_starts(grade_histological_differentiation_imp, "Moderately") ~ 2,
      str_starts(grade_histological_differentiation_imp, "Poorly") ~ 3, 
      TRUE ~ NA_real_
    ))) 
  
  # Convert categorical to numeric
  data_dummies <- dummy_cols(
    .data = data_transf, 
    select_columns = NULL, 
    remove_first_dummy = TRUE, 
    remove_selected_columns = TRUE
    )
  
  # Transform covariates dataframe into matrix
  covariates <- as.matrix(data_dummies)
  
  # Scale 
  if (apply_scaling == TRUE) {
    covariates <- scale(covariates)
  }
  
  return(covariates)
}
```


```{r}
oncoth1_transf <- process_data(oncoth1_survival_df, cols2select = cols2select)
```


```{r}
Y0 <- with(oncoth1_survival_df, Surv(time, death))
Y0
```



```{r}
alpha = 0.1

lasso_cox <- glmnet(
  x = oncoth1_transf, 
  y = Y0, 
  family = "cox", 
  alpha = alpha
)

coef(lasso_cox, s = alpha)

linear_pred <- as.numeric(predict(lasso_cox, newx = oncoth1_transf, s = alpha, type = "link"))

cindex <- concordance(Y0 ~ linear_pred)
print(cindex)
```


```{r}
# # Train your model on the training fold
# model = StepReg::stepwiseCox(
#   formula = Surv(time = tstart, time2 = tstop, event = death) ~
#   vte_event +
#   age_when_cancer_dx +
#   gender +
#   bmi_value +
#   performance_status_category_corrected_imp + # Multicollinearity with cancer type, tobacco use, tumor resection in some folds, but models can be trained
#   # diabetes_mellitus + # Confounder. We kfoldsnow it is associated with pancreatic cancer patients that undergo resection of pancreas
#   dyslipidemia +
#   # tobacco_use_imp + # Correlated to NSCLC. Multicollinearity if PS is also selected
#   # copd_imp + # Correlated to tobacco use
#   arterial_hypertension +
#   # venous_insufficiency_imp +  # remove as suggested by Andrés Muñoz (bad definition of variable, information may refer to different conditions)
#   # kfoldshorana_riskfolds_score_imp + # Correlated to pancreatic and esophago-gastric cancers
#   # two_groups_kfoldsrs + # Correlated to pancreatic and esophago-gastric cancers
#   # previous_onco_surgery + # Correlated to having had tumor resected
#   tumor_surgically_removed +
#   primary_tumor_simplified +
#   # tnm_stage_grouped +
#   tnm_stage_two_groups +
#   # histology_type_imp + # Correlated with NSCLC
#   mucinous_histology_imp +
#   # grade_histological_differentiation_imp + # violates PH assumption
#   # catheter_device_imp + # quite correlated with tumor type, as Cramer's V indicates
#   # family_backfoldsground_vte + # High GVIF, multicollinearity with venous insufficiency in some folds. When selected, not clear if it is riskfolds or protective factor, due to lackfolds of information when recruiting patients
#   previous_vte +
#   previous_ate +
#   anticoag_tx_currently +
#   antiaggreg_tx_currently,
#   data = training_fold,
#   include = "primary_tumor_simplified",
#   selection = "bidirection",
#   select = "AIC",
#   method = "efron"
#   )
```



## Inspect correlation

```{r}
# Calculate correlation
corr_covariates <- oncoth1_transf %>% cor(.)
```


```{r}
# Interactive heatmap
plot_ly(
  data = reshape2::melt(corr_covariates),
  x = ~Var1,
  y = ~Var2,
  z = ~value,
  type = "heatmap",
  colors = colorRamp(c("blue", "white", "red")),
  colorbar = list(title = "Correlation"),
  showscale = TRUE
  ) %>%
  layout(
    title = "Interactive Heatmap of Correlations in ONCOTHROMB1",
    xaxis = list(title = "Variables"),
    yaxis = list(title = "Variables")
  )
```


## Dataset partition

```{r}
# Partition data with repeated rows per patient into training and test set
ids_row_map <- data.frame(
  "row" = row.names(oncoth1_survival_df), 
  "id" = oncoth1_survival_df$id
  )

# Get unique IDs
unique_ids <- unique(oncoth1_survival_df$id)

# Randomly assign each unique ID to either train or test
train_ids <- sample(unique_ids, size = floor(0.8 * length(unique_ids))) # 80% for training
test_ids <- setdiff(unique_ids, train_ids)  # Remaining IDs for testing

# No match between train and test IDs
stopifnot(train_ids != test_ids)

# Get rows of train and test patients
train_rows <- which(oncoth1_survival_df$id %in% train_ids)
test_rows <- which(oncoth1_survival_df$id %in% test_ids)

# No match between train and test rows
stopifnot(train_rows != test_rows)
```


```{r}
# Save IDs in training and test split
write.csv(x = train_ids, file = "../partition_indices/glmnet_train_ids.csv", row.names = FALSE)
write.csv(x = test_ids, file = "../partition_indices/glmnet_test_ids.csv", row.names = FALSE)

# Save row number in training and test split
write.csv(x = train_rows, file = "../partition_indices/glmnet_train_rows.csv", row.names = FALSE)
write.csv(x = test_rows, file = "../partition_indices/glmnet_test_rows.csv", row.names = FALSE)
```


```{r}
# Create target variable
y <- with(oncoth1_survival_df, Surv(time, death))
```


```{r}
# Partition data using rows
training_set <- oncoth1_survival_df[train_rows,]
test_set <- oncoth1_survival_df[test_rows,]

# Partition target
y_train <- y[train_rows]
y_test <- y[test_rows]

# Check that all patients are accounted for in training and test set
stopifnot(
  nrow(training_set) + nrow(test_set) == nrow(oncoth1_transf),
  length(y_train) + length(y_test) == length(y)
)
```


```{r}
# Number of folds
kfolds <- 10
```


```{r}
# Create a fold-map at the patient level
shuffled_ids <- sample(unique_ids)
fold_sizes <- floor(length(shuffled_ids) / kfolds)
remainder <- length(shuffled_ids) %% kfolds

fold_vec <- rep(
  1:kfolds, 
  times = c(
    rep(fold_sizes + 1, remainder), 
    rep(fold_sizes, kfolds - remainder)
  )
)
# Tibble with IDs and folds mapped
fold_map <- tibble(id = shuffled_ids, fold = fold_vec)

# Join to have row number
cv_info_mapping <- fold_map %>%
  left_join(ids_row_map, by = "id") %>%
  mutate(set = case_when(
    id %in% train_ids ~ "train",
    id %in% test_ids ~ "test"
    )
    )
```


```{r}
# Cross-validation loop
set.seed(seed)

# Define lambda grid
alpha_grid <- c(0.001, 0.01, 0.1, 1, 5, 10)
# alpha_grid <- 1

# Store regularization pathway results
# Do combinations of all folds and lambda1 values
cv_out <- expand.grid(
  alpha = alpha_grid, 
  fold = 1:kfolds, 
  stringsAsFactors = FALSE
  ) %>%
  as_tibble() %>%
  mutate(
    cindex = NA_real_, 
    selected_vars = vector("list", n())
  )

# 
# vif_results <- vector("list", length = k)

# Loop over each row of that tibble
for (i in seq_len(nrow(cv_out))) {
  # Get alpha and fold from tibble with combinations
  alpha <- cv_out$alpha[i]
  i_fold <- cv_out$fold[i]
  
  # Get validation row number those not in this fold
  valid_ids <- cv_info_mapping %>% 
    filter(set == "train", fold == i_fold) %>% 
    pull(id) %>%
    as.integer()
  # Get train row number
  tr_ids <- cv_info_mapping %>% 
    filter(set == "train", fold != i_fold) %>% 
    pull(id) %>%
    as.integer()
  
  # Sanity check
  stopifnot(!valid_ids %in% tr_ids)
  
  # Subset data
  valid_data <- training_set %>% filter(id %in% valid_ids)
  tr_data <- training_set %>% filter(id %in% train_ids)
  
  # Sanity check
  stopifnot(
    all(tr_data$id %in% train_ids), 
    all(valid_data$id %in% valid_ids)
  )
  
  # Select covariates
  valid_data_subset <- process_data(valid_data, cols2select)
  tr_data_subset <- process_data(tr_data, cols2select)
  
  # Learn scaling parameters on train data
  preproc <- caret::preProcess(
    x = tr_data_subset,
    method = c("center", "scale")
  )
  # Scale data
  X_train <- predict(preproc, tr_data_subset)
  X_valid <- predict(preproc, valid_data_subset)
  
  
}
```


## Regularization pathway

```{r}
# Summarize mean C-index by lambda1
summary_regpath <- regpath_results %>%
  group_by(lambda1) %>%
  summarise(
    mean_cindex = mean(cindex, na.rm = TRUE), 
    .groups = "drop"
  )
summary_regpath
```


```{r}
ggplot(summary_regpath, aes(x = lambda1, y = mean_cindex)) + 
  geom_line(size = 1) + 
  geom_point(size = 2) + 
  scale_x_log10(
    breaks = unique(summary_regpath$lambda1), 
    labels = scales::scientific_format(digits = 2)
  ) + 
  labs(
    x = expression(log[10](lambda[1])), 
    y = "Mean CV C-index", 
    title = "Regularization path: mean C-index vs penalty strength"
  ) + 
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5), 
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

## More frequently selected variables

```{r}
freq_selected_vars <- regpath_results %>%
  mutate(
    selected = map(
      selected_vars, 
      ~ names(.x)[.x != 0] # get variables names with non-zero weights
    )
  ) %>%
  # Keep lambda/fold id and list of selected variables
  select(lambda1, fold, selected) %>%
  # Explode the list-column to have lambda, fold and vars in one row
  unnest(selected) %>%
  # Count how many times each variable appears
  count(variable = selected, name = "freq") %>%
  mutate(rel_freq = freq / nrow(regpath_results)) %>%
  arrange(desc(rel_freq))

freq_selected_vars
```



```{r}
aa
```

```{r}
# Then, train final model with selected features and compute C-index on test set
# ...
```






