---
title: "Lasso Cox Regression"
author: "Bárbara Lobato Delgado"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Settings and load libraries

```{r}
# Deactivate scientific notation
options(scipen = 999, max.print = 10000)

# Seed
seed = 2828
set.seed(seed)
```


```{r}
find_column_mismatch <- function(df1, df2) {
  # Find column mismatch
  missing_in_valid <- setdiff(colnames(df1), colnames(df2))
  extra_in_valid <- setdiff(colnames(df2), colnames(df1))
  
  if (length(missing_in_valid) > 0 || length(extra_in_valid) > 0) {
    msg <- c()
    if (length(missing_in_valid) > 0) {
      msg <- c(msg, sprintf("Columns missing in validation: %s", 
                            paste(missing_in_valid, collapse = ", ")))
    }
    if (length(extra_in_valid) > 0) {
      msg <- c(msg, sprintf("Extra columns in validation: %s",
                          paste(extra_in_valid, collapse = ", ")))
    }
    stop(paste(msg, collapse = "; "), call. = FALSE)
  }
}
```


```{r}
# Load libraries
pacman::p_load(
  an9elproject, 
  tidyverse,
  lubridate, 
  magrittr,
  fastDummies,
  glmnet,
  survival,
  survminer, 
  penalized,
  powerSurvEpi,
  car,
  StepReg,
  plotly,
  install = FALSE, update = FALSE
  )
```

## Load data

```{r cars}
# Load time-dependent dataset
oncoth1_td_dataset = read.csv(file = "/mnt/ir-bioinf02/home/blobato/oncothromb01/data/processed/oncoth1_td_dataset.csv")
```


```{r}
# Remove columns with missing values
oncoth1_td_dataset %<>%
  select(where(~ !any(is.na(.))))

# Stop if there are missing values in dataset
stopifnot(!anyNA(oncoth1_td_dataset))
```


```{r}
# Get meaningful variables
oncoth1_td_dataset_selected_vars <- oncoth1_td_dataset %>%
  select(vte_event,
         age_when_cancer_dx, 
         gender, 
         bmi_value, 
         performance_status_category_corrected_imp, 
         diabetes_mellitus,
         dyslipidemia, 
         arterial_hypertension, 
         tobacco_use_imp, 
         copd_imp, 
         venous_insufficiency_imp, 
         khorana_risk_score_imp, 
         two_groups_krs,
         previous_onco_surgery,
         tumor_surgically_removed, 
         primary_tumor_simplified, 
         tnm_stage_grouped, 
         tnm_stage_two_groups, 
         histology_type_imp,
         mucinous_histology_imp,
         grade_histological_differentiation_imp,
         catheter_device_imp, 
         family_background_vte, 
         previous_vte,  
         previous_ate, 
         anticoag_tx_currently, 
         antiaggreg_tx_currently
         )
```

```{r}
# # Train your model on the training fold
# model = StepReg::stepwiseCox(
#   formula = Surv(time = tstart, time2 = tstop, event = death) ~
#   vte_event +
#   age_when_cancer_dx +
#   gender +
#   bmi_value +
#   performance_status_category_corrected_imp + # Multicollinearity with cancer type, tobacco use, tumor resection in some folds, but models can be trained
#   # diabetes_mellitus + # Confounder. We kfoldsnow it is associated with pancreatic cancer patients that undergo resection of pancreas
#   dyslipidemia +
#   # tobacco_use_imp + # Correlated to NSCLC. Multicollinearity if PS is also selected
#   # copd_imp + # Correlated to tobacco use
#   arterial_hypertension +
#   # venous_insufficiency_imp +  # remove as suggested by Andrés Muñoz (bad definition of variable, information may refer to different conditions)
#   # kfoldshorana_riskfolds_score_imp + # Correlated to pancreatic and esophago-gastric cancers
#   # two_groups_kfoldsrs + # Correlated to pancreatic and esophago-gastric cancers
#   # previous_onco_surgery + # Correlated to having had tumor resected
#   tumor_surgically_removed +
#   primary_tumor_simplified +
#   # tnm_stage_grouped +
#   tnm_stage_two_groups +
#   # histology_type_imp + # Correlated with NSCLC
#   mucinous_histology_imp +
#   # grade_histological_differentiation_imp + # violates PH assumption
#   # catheter_device_imp + # quite correlated with tumor type, as Cramer's V indicates
#   # family_backfoldsground_vte + # High GVIF, multicollinearity with venous insufficiency in some folds. When selected, not clear if it is riskfolds or protective factor, due to lackfolds of information when recruiting patients
#   previous_vte +
#   previous_ate +
#   anticoag_tx_currently +
#   antiaggreg_tx_currently,
#   data = training_fold,
#   include = "primary_tumor_simplified",
#   selection = "bidirection",
#   select = "AIC",
#   method = "efron"
#   )
```



```{r}
# Change name of dependent variable
oncoth1_td_data_clean <- dummy_cols(
  .data = oncoth1_td_dataset_selected_vars, 
  select_columns = NULL, 
  remove_first_dummy = TRUE, 
  remove_selected_columns = TRUE
  )
# Sanity check
stopifnot(!anyNA(oncoth1_td_data_clean))

oncoth1_td_data_clean
```


```{r}
# Transform covariates dataframe into matrix
covariates <- as.matrix(oncoth1_td_data_clean)
stopifnot(!anyNA(covariates))
# Scale 
covariates_scaled <- scale(covariates)
stopifnot(!anyNA(covariates_scaled))
```


```{r}
# Create response Surv() object
# Allow for right-censoring to handle time-dependent variables
response = with(oncoth1_td_dataset, Surv(tstart, tstop, death))
response[1:5]
```

```{r}
# Covariates matrix and response must have same length (number of patients)
stopifnot(dim(covariates)[0] == length(response))
```


```{r}
library(penalized)

fit <- penalized(
  response    = response, 
  penalized  = covariates_scaled,
  unpenalized = ~1,
  lambda1     = 10,        # your LASSO penalty
  model       = "cox"
)

```

```{r}
coef(fit)
```


```{r}
cols2select <- c(
 "vte_event",
 "age_when_cancer_dx", 
 "gender", 
 "bmi_value", 
 "performance_status_category_corrected_imp", 
 "diabetes_mellitus",
 "dyslipidemia", 
 "arterial_hypertension", 
 "tobacco_use_imp", 
 "copd_imp", 
 "venous_insufficiency_imp", 
 "khorana_risk_score_imp", 
 "two_groups_krs",
 "previous_onco_surgery",
 "tumor_surgically_removed", 
 "primary_tumor_simplified", 
 "tnm_stage",
 # "tnm_stage_grouped", 
 # "tnm_stage_two_groups", 
 # "histology_type_imp", # unequal categories between train and validation set
 "mucinous_histology_imp",
 "grade_histological_differentiation_imp",
 "catheter_device_imp", 
 # "family_background_vte", 
 # "previous_vte",  
 "previous_ate", 
 # "anticoag_tx_currently", # unequal categories between train and validation set
 "antiaggreg_tx_currently"
 )
```


```{r}
process_data <- function(data, cols2select) {
  
  missing_cols <- setdiff(cols2select, colnames(data))
  if (length(missing_cols) > 0) {
    stop(paste("The following columns are missing from the data:", 
               paste(missing_cols, collapse = ", ")))
  }
  
  # Select columns as dependent variables
  data_selection <- data[, cols2select]
  
  # Convert yes/no columns into 1/0
  data_selection <- data_selection %>%
    mutate(
      across(
        .cols = where(~ (is.character(.) || is.factor(.)) && 
                        all(as.character(.) %in% c("Yes", "No"))), 
        .fns = ~ as.integer(as.character(.) == "Yes")
      )
    )
  
  # Transform other columns to numerical
  data_transf <- data_selection %>%
    mutate(grade_histological_differentiation_imp = as.numeric(case_when(
      str_starts(grade_histological_differentiation_imp, "Well") ~ 1,
      str_starts(grade_histological_differentiation_imp, "Moderately") ~ 2,
      str_starts(grade_histological_differentiation_imp, "Poorly") ~ 3, 
      TRUE ~ NA_real_
    ))) %>%
    mutate(tnm_stage = as.numeric(case_when(
      tnm_stage == "I" ~ 1,
      tnm_stage == "II" ~ 2,
      tnm_stage == "III" ~ 3,
      tnm_stage == "IV" ~ 4, 
      TRUE ~ NA_real_
    )))
  
  # print(colnames(data_transf))
  
  # Convert categorical to numeric
  data_dummies <- dummy_cols(
    .data = data_transf, 
    select_columns = NULL, 
    remove_first_dummy = TRUE, 
    remove_selected_columns = TRUE
    )
  
  # Transform covariates dataframe into matrix
  covariates <- as.matrix(data_dummies)
  # Scale 
  covariates_scaled <- scale(covariates)
  
  return(covariates_scaled)
}
```


```{r}
processed_oncoth1 <- process_data(oncoth1_td_dataset, cols2select)
```


## Dataset partition

```{r}
# Partition data with repeated rows per patient into training and test set

# Get unique IDs
unique_ids <- unique(oncoth1_td_dataset$id)

# Randomly assign each unique ID to either train or test
train_ids <- sample(unique_ids, size = floor(0.8 * length(unique_ids))) # 80% for training
test_ids <- setdiff(unique_ids, train_ids)  # Remaining IDs for testing

# # Get rows of train and test patients
# train_rows <- which(oncoth1_td_dataset$id %in% train_ids)
# test_rows <- which(oncoth1_td_dataset$id %in% test_ids)
# 
# # Partition data keeping the IDs (needed for stratified CV)
# training_set_with_ids <- oncoth1_td_dataset %>% 
#   filter(id %in% train_ids) %>% 
#   select(id)
# testing_set_with_ids <- oncoth1_td_dataset %>% 
#   filter(id %in% test_ids) %>%
#   select(id)

# Partition data
training_set <- oncoth1_td_dataset %>% filter(id %in% train_ids)
test_set <- oncoth1_td_dataset %>% filter(id %in% test_ids)
# training_set <- oncoth1_td_dataset[train_rows,]
# test_set <- oncoth1_td_dataset[test_rows,]
# training_set <- covariates[train_rows,]
# test_set <- covariates[test_rows,]

# Checkfolds that IDs are not in training and test sets
stopifnot(
  identical(
    sort(unique(training_set$id)), sort(unique(test_set$id))) == FALSE)

# # Partition response
# training_response <- response[train_rows,]
# test_response <- response[test_rows,]

# Surv response for full data
response = with(oncoth1_td_dataset, Surv(tstart, tstop, death))
train_rows <- which(oncoth1_td_dataset$id %in% train_ids)
test_rows <- which(oncoth1_td_dataset$id %in% test_ids)
# Get response for training and test sets
training_response <- response[train_rows]
test_response <- response[test_rows]

# Check that all patients are accounted for in training and test set
stopifnot(dim(training_set)[0] + dim(test_set)[0] == covariates)
stopifnot(length(training_response) + length(test_response) == length(response))
```


```{r}
# # Partition the data into train and test sets based on the assigned IDs
# training_set <- oncoth1_td_dataset %>% filter(id %in% train_ids)
# testing_set <- oncoth1_td_dataset %>% filter(id %in% test_ids)
# 
# # Checkfolds that IDs are not in training and test sets
# stopifnot(
#   identical(
#     sort(unique(training_set$id)), sort(unique(testing_set$id))) == FALSE)
```


```{r}
# Create folds for k-fold CV

# Number of folds
kfolds <- 10

# Create a grouping variable for each ID
unique_train_ids <- unique(train_ids)

# Shuffle and assign
shuffled_train_ids <- sample(unique_train_ids)
# Get size for each fold
fold_sizes <- floor(length(shuffled_train_ids) / kfolds)
remainder <- length(shuffled_train_ids) %% kfolds
fold_vec <- rep(
  1:kfolds, 
  times = c(rep(fold_sizes + 1, remainder), 
            rep(fold_sizes, kfolds - remainder))
)

# Map each ID to each fold
fold_map <- data.frame(
  patient_id = shuffled_train_ids,
  fold = fold_vec
)
```


```{r}
# Cross-validation loop
set.seed(seed)

# Define lambda grid
lambda1_grid <- c(0.001, 0.01, 0.1, 1, 5, 10)
# lambda1_grid <- 1
# lambda1_grid <- 10^seq(-4, 2, length.out = 50)

# Store regularization pathway results
# Do combinations of all folds and lambda1 values
regpath_results <- expand.grid(
  lambda1 = lambda1_grid, 
  fold = seq_len(kfolds), 
  KEEP.OUT.ATTRS = FALSE, 
  stringsAsFactors = FALSE
) %>%
  as_tibble() %>%
  mutate(
    cindex = NA_real_, 
    selected_vars = vector("list", n())
  )

# Loop over each row of tha tibble
for (row_idx in seq_len(nrow(regpath_results))) {
  
  # Select lambda and fold value
  l1 <- regpath_results$lambda1[row_idx]
  fold_i <- regpath_results$fold[row_idx]
  
  # print("------------")
  # print(paste0("Loop #", fold_i))
  # print("------------")
  
  # Determine training and validation patient IDs
  validation_ids <- fold_map$patient_id[fold_map$fold == fold_i]
  training_ids <- setdiff(unique_train_ids, validation_ids)
  
  # Subset interval-level data
  valid_data <- training_set %>% filter(id %in% validation_ids)
  train_data <- training_set %>% filter(id %in% training_ids)
  
  # Sanity checks
  stopifnot(
    setequal(validation_ids, unique(valid_data$id)),
    setequal(training_ids, unique(train_data$id))
  )
  
  # Process data
  X_valid <- process_data(valid_data, cols2select)
  X_train <- process_data(train_data, cols2select)
  
  # Check that there are no missing values
  # na_per_col <- colSums(is.na(X_valid))
  # print("Showing NAs per column")
  # na_per_col[na_per_col > 0]
  # print(na_per_col)
  stopifnot(!anyNA(X_valid))
  stopifnot(!anyNA(X_train))
  
  # Find column mismatch if there is one
  find_column_mismatch(X_valid, X_train)
  
  # Get responses
  y_valid <- with(valid_data, Surv(tstart, tstop, death))
  y_train <- with(train_data, Surv(tstart, tstop, death))
  
  # Fit penalized Cox on training fold
  pencox_cv <- penalized(
    response = y_train,
    penalized = X_train,
    unpenalized = ~1, 
    lambda1 = l1,
    lambda2 = 0,
    model = "cox", 
    trace = FALSE
  )
  
  # Get coefficients for all initial predictors
  b <- coef(pencox_cv, "all", standardize = TRUE)
  
  # Sanity check
  stopifnot(names(b) == colnames(X_valid))
  
  # Compute the linear predictor η = β′X
  lp_valid <- as.numeric(X_valid %*% b)
  
  # Evaluate using C-index
  regpath_results$cindex[row_idx] <- survival::concordance(y_valid ~ lp_valid)$concordance
  
  # Record selected variables
  regpath_results$selected_vars[[row_idx]] <- coef(pencox_cv)
}
```


```{r}
# Summarize mean C-index by lambda1
summary_regpath <- regpath_results %>%
  group_by(lambda1) %>%
  summarise(
    mean_cindex = mean(cindex, na.rm = TRUE), 
    .groups = "drop"
  )
summary_regpath
```


```{r}
ggplot(summary_regpath, aes(x = lambda1, y = mean_cindex)) + 
  geom_line(size = 1) + 
  geom_point(size = 2) + 
  scale_x_log10(
    breaks = unique(summary_regpath$lambda1), 
    labels = scales::scientific_format(digits = 2)
  ) + 
  labs(
    x = expression(log[10](lambda[1])), 
    y = "Mean CV C-index", 
    title = "Regularization path: mean C-index vs penalty strength"
  ) + 
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5), 
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

```{r}
freq_selected_vars <- regpath_results %>%
  mutate(
    selected = map(
      selected_vars, 
      ~ names(.x)[.x != 0] # get variables names with non-zero weights
    )
  ) %>%
  # Keep lambda/fold id and list of selected variables
  select(lambda1, fold, selected) %>%
  # Explode the list-column to have lambda, fold and vars in one row
  unnest(selected) %>%
  # Count how many times each variable appears
  count(variable = selected, name = "freq") %>%
  mutate(rel_freq = freq / nrow(regpath_results)) %>%
  arrange(desc(rel_freq))

freq_selected_vars
```



```{r}
aa
```

```{r}
# Then, train final model with selected features and compute C-index on test set
# ...
```


```{r}
# # Cross-validation loop
# set.seed(seed)
# 
# # Store resutls
# cv_cindex <- numeric(kfolds)
# cv_selected_vars <- vector("list", kfolds)
# 
# for (i in seq_len(kfolds)) {
#   
#   print("------------")
#   print(paste0("Loop #", i))
#   print("------------")
#   
#   # Determine training and validation patient IDs
#   validation_ids <- fold_map$patient_id[fold_map$fold == i]
#   training_ids <- setdiff(unique_train_ids, validation_ids)
#   
#   # Subset interval-level data
#   valid_data <- training_set %>% filter(id %in% validation_ids)
#   train_data <- training_set %>% filter(id %in% training_ids)
#   
#   # Sanity checks
#   stopifnot(
#     setequal(validation_ids, unique(valid_data$id)),
#     setequal(training_ids, unique(train_data$id))
#   )
#   
#   # Process data
#   X_valid <- process_data(valid_data, cols2select)
#   X_train <- process_data(train_data, cols2select)
#   
#   # Check that there are no missing values
#   # na_per_col <- colSums(is.na(X_valid))
#   # print("Showing NAs per column")
#   # na_per_col[na_per_col > 0]
#   # print(na_per_col)
#   stopifnot(!anyNA(X_valid))
#   stopifnot(!anyNA(X_train))
#   
#   # Find column mismatch if there is one
#   find_column_mismatch(X_valid, X_train)
#   
#   # Get responses
#   y_valid <- with(valid_data, Surv(tstart, tstop, death))
#   y_train <- with(train_data, Surv(tstart, tstop, death))
#   
#   # Fit penalized Cox on training fold
#   pencox_cv <- penalized(
#     response = y_train,
#     penalized = X_train,
#     unpenalized = ~1, 
#     lambda1 = 10,
#     lambda2 = 0.1,
#     model = "cox", 
#     trace = TRUE
#   )
#   
#   # Get coefficients for all initial predictors
#   b <- coef(pencox_cv, "all")
#   
#   # Sanity check
#   stopifnot(length(b) == ncol(X_valid))
#   
#   # Compute the linear predictor η = β′X
#   lp_valid <- as.numeric(X_valid %*% b)
#   
#   # Evaluate using C-index
#   cv_cindex[[i]] <- survival::concordance(y_valid ~ lp_valid)$concordance
#   
#   # Record selected variables
#   cv_selected_vars[[i]] <- coef(pencox_cv) # names(coefs)[which(coefs != 0)]
# 
#   message(sprintf(
#     "Fold %d: C-index = %.4f; Selected %d vars",
#     i,
#     cv_cindex[[i]],
#     length(cv_selected_vars[[i]])
#   ))
#   
# }
```






